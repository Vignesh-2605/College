#1 Arithmetic operations
a <- 8; b <- 2  
print(a + b); print(a - b); print(a * b); print(a / b); print(a ^ b)  

#2 Data frame with emp details
d <- data.frame(ID = c(1, 2, 3), Name = c("A", "B", "C"), Age = c(25, 30, 22), Salary = c(5000, 6000, 4000))  
d$Dept <- c("HR", "IT", "Finance"); d_sorted <- d[order(d$Salary), ]  
print(d); print(d_sorted)  

#3 Slicing, reshaping and sum of elements 
m <- matrix(1:12, nrow = 3)  
print(m[1:2, ]); print(t(m)); print(sum(m))  

#4 Sequence, Mean, and Sum
print(20:50); print(mean(20:60)); print(sum(51:91))  

#5 Extract Letters
cat(letters[1:10]); print(LETTERS[17:26]); print(LETTERS[22:24])  

#6 Logical Vector
v <- c(1, 2, 3, 4, 5)  
print(v); print(v[v > 2 & v < 5]); print(v[v<2 | v>5])

#7 Factors
c <- c("red", "blue", "green")  
f <- factor(c); levels(f) <- c("R", "B", "G")  
print(f); print(levels(f))  

#8 Data Types and Conversion
n <- 10; i <- as.integer(n); ch <- as.character(i); lg <- as.logical(i); cm <- 3 + 2i  
print(n); print(i); print(ch); print(lg); print(cm)  

#9 Matrices
print(matrix(1:20, nrow = 5, ncol = 4))  
print(matrix(1:9, nrow = 3, byrow = TRUE))  
print(matrix(1:4, nrow = 2, byrow = FALSE))  

#10 Two-Dimensional Array
print(array(seq(52, 76, by = 2), dim = c(5, 3, 2)))  

#11 Access Values in a Vector
v <- c(1, 3, 5, 7, 9)  
print(v); print(v[1:3])  

#12 Nth Smallest Value in Vector
v <- c(9, 2, 5, 7, 1); n <- 3  
print(sort(v)[n])  

#13 Concatenate Vector of Strings
v <- c("Hello", "World", "R")  
print(paste(v, collapse = " "))  

#14 Matrix Max/Min Index
m <- matrix(1:9, nrow = 3)  
print(which(m == max(m), arr.ind = TRUE))  
print(which(m == min(m), arr.ind = TRUE))  

#15 Fizz Buzz
for (i in 1:100) {  
  if (i %% 3 == 0 & i %% 5 == 0) print("FizzBuzz")  
  else if (i %% 3 == 0) print("Fizz")  
  else if (i %% 5 == 0) print("Buzz")  
  else print(i)  
}  

#16 List to Data Frame
l <- list(ID = c(1, 2), Name = c("A", "B"), Age = c(25, 30))  
print(data.frame(l))  

#17 Employee Summary
d <- data.frame(ID = c(1, 2, 3, 4, 5), Name = c("A", "B", "C", "D", "E"), Age = c(25, 30, 22, 27, 29), Salary = c(5000, 6000, 4000, 5500, 7000))  
print(d); print(summary(d))  

#18 Max and Min of Vector
v <- c(5, 2, 9, 1, 7)  
print(max(v)); print(min(v))  

#19 3D Array
print(array(1:18, dim = c(3, 3, 2)))  

#20 Assign Grades
s <- 85  
if (s >= 90) g <- "A" else if (s >= 80) g <- "B" else if (s >= 70) g <- "C" else g <- "D"  
print(g)  

# 21. Factorial using a for loop
factorial_loop <- function(num) {
  if (num < 0) {
    return("Error: Factorial of a negative number is undefined.")
  }
  if (num == 0) {
    return(1)
  }
  fac <- 1
  for (i in 1:num) {
    fac <- fac * i
  }
  return(fac)
}
print(factorial_loop(5))

# 22. Fibonacci sequence using while loop
fibonacci_while <- function(lim) {
  f1 <- 0
  f2 <- 1
  fib <- c(f1, f2)
  while (TRUE) {
    nxt <- f1 + f2
    if (nxt > lim) break
    fib <- c(fib, nxt)
  f1 <- f2
  f2 <- nxt
}
print(fib)
print(length(fib))
}
fibonacci_while(10)

# 23. Assign grade based on score
assign_grade <- function(score) {
  if (score >= 90) {
    return("A")
  } else if (score >= 80) {
    return("B")
  } else if (score >= 70) {
    return("C")
  } else if (score >= 60) {
    return("D")
  } else {
    return("F")
  }
}
print(assign_grade(85))

# 24. Mean of numeric vectors ignoring non-numeric values
mean_ignore_na <- function(lst) {
  means <- sapply(lst, function(x) {
    x <- as.numeric(x)  # Convert to numeric
    x <- x[!is.na(x)]   # Remove NAs introduced by coercion
    if (length(x) == 0) return(NA)  # Handle cases where all elements are NA
    return(mean(x, na.rm = TRUE))  # Compute mean
  })
  return(means)
}


print(mean_ignore_na(list(c(1, 2, "a", 3), c(4, 5, NA, 6))))

# 25. Print rows from data frame meeting a condition
filter_age <- function(df) {
  print(df[df$Age > 30, ])
}
df <- data.frame(Name = c("Alice", "Bob"), Age = c(25, 35))
filter_age(df)

# 26. Basic arithmetic operations
arithmetic_ops <- function(a, b) {
  return(list(sum = a + b, diff = a - b, prod = a * b, quot = a / b))
}
print(arithmetic_ops(10, 5))

# 27. Attendance or exam pass
check_attendance <- function(att, exam) {
  return(att >= 75 || exam >= 50)
}
print(check_attendance(80, 40))

# 28. Mean, Median, Mode function
calc_stats <- function(vec) {
  mode_val <- as.numeric(names(sort(table(vec), decreasing = TRUE)[1]))
  return(list(mean = mean(vec), median = median(vec), mode = mode_val))
}
print(calc_stats(c(1, 2, 2, 3, 4)))

# 29. Recursive factorial
factorial_recursive <- function(n) {
  if (n == 0) return(1)
  return(n * factorial_recursive(n - 1))
}
print(factorial_recursive(5))

# 30. Recursive Fibonacci
fibonacci_recursive <- function(n) {
  if (n <= 1) return(n)
  return(fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2))
}
print(fibonacci_recursive(6))

# 31. Vector iteration with arithmetic function
vector_arithmetic <- function(vec) {
  return(sapply(vec, function(x) x * 2))
}
print(vector_arithmetic(c(1, 2, 3)))

# 32. Rectangle area with default values
rectangle_area <- function(l = 5, w = 10) {
  return(l * w)
}
print(rectangle_area())
print(rectangle_area(7, 8))

# 33. Prime number check
is_prime <- function(n) {
  if (n < 2) return(FALSE)
  for (i in 2:sqrt(n)) {
    if (n %% i == 0) return(FALSE)
  }
  return(TRUE)
}
print(is_prime(11))

# 34. Recursive sum of vector
sum_recursive <- function(vec) {
  if (length(vec) == 0) return(0)
  return(vec[1] + sum_recursive(vec[-1]))
}
print(sum_recursive(c(1, 2, 3, 4)))

# 35. Assign grade based on criteria
print(assign_grade(78))

# 36. Replace values in vector
replace_values <- function(vec) {
  return(ifelse(vec > 0, "positive", ifelse(vec < 0, "negative", "zero")))
}
print(replace_values(c(-1, 0, 1)))

# 37. Loop over character vector categories
category_counts <- function(lst) {
  for (cat in names(lst)) {
    print(paste(cat, length(lst[[cat]])))
  }
}
category_counts(list(Fruits = c("Apple", "Banana"), Electronics = c("Phone")))

# 38. Find duplicated products and unique customer-product pairs
find_duplicate_products <- function(cust, prod) {
  df <- data.frame(Customer = cust, Product = prod)
  print(df[duplicated(df$Product), ])
  print(unique(df))
}
find_duplicate_products(c("A", "B", "A", "C"), c("X", "Y", "Z", "W"))

# 39. Identify duplicated treatments for patients
find_duplicate_treatments <- function(pat, treat) {
  df <- data.frame(Patient = pat, Treatment = treat)
  print(df[duplicated(df$Treatment), ])
  print(unique(df))
}
find_duplicate_treatments(c("P1", "P2", "P3", "P1"), c("T1", "T2", "T1", "T3"))

# 40. Find duplicate treatments and summarize unique patient-treatment pairs
find_treatment_duplicates <- function(pat, treat) {
  df <- data.frame(Patient = pat, Treatment = treat)
  print(df[duplicated(df$Treatment), ])
  print(aggregate(Treatment ~ Patient, data = df, FUN = unique))
}
find_treatment_duplicates(c("P1", "P2", "P1", "P3"), c("T1", "T2", "T1", "T3"))

# Question 41: Create and Print Data Frame
df <- data.frame(Name = c("John","Jane", "Doe", "Mary"), 
                 Age = c(25, 30, 35, 40), 
                 Gender = c("M", "F","M", "F"))
print(df)

# Question 42: Extract Height Column as Vector
df <- data.frame(Age = c(25, 30, 35, 40), Height = c(160, 170, 165, 175))
height_vector <- df$Height
print(height_vector)

# Question 43: Convert Data Frame to Long Format using melt
# First install reshape2 if not already installed
if (!require(reshape2)) install.packages("reshape2")
library(reshape2)

sale <- data.frame(region = c("North", "South", "East", "West"), 
                   Q1 = c(100, 200, 150, 180), 
                   Q2 = c(120, 210, 160, 190), 
                   Q3 = c(130, 220, 170, 200), 
                   Q4 = c(140, 230, 180, 210))
melted_sale <- melt(sale, id.vars = "region", variable.name = "quarter", value.name = "sales")
print(melted_sale)

# Question 44: Process AirQuality Dataset
data("airquality")
print(is.data.frame(airquality))
ordered_airquality <- airquality[order(airquality$Ozone, airquality$Solar.R), ]
ordered_airquality <- ordered_airquality[, !(names(ordered_airquality) %in% c("Solar.R", "Wind"))]
print(head(ordered_airquality))

# Question 45: Create Factor from Women Dataset
data("women")
height_factor <- factor(women$height)
print(height_factor)

# Question 46: EDA on Iris Dataset
data("iris")
print(dim(iris))
print(str(iris))
print(summary(iris))
print(sapply(iris[,1:4], sd))

# Question 47: Logistic Regression on Iris (simplified to binary classification)
# Convert to binary classification problem (setosa vs not setosa)
iris_binary <- iris
iris_binary$is_setosa <- ifelse(iris_binary$Species == "setosa", 1, 0)

set.seed(123)
train_indices <- sample(1:nrow(iris_binary), 0.8 * nrow(iris_binary))
train_data <- iris_binary[train_indices, ]
test_data <- iris_binary[-train_indices, ]

model <- glm(is_setosa ~ Petal.Length + Petal.Width, 
             data = train_data, 
             family = binomial(link = "logit"))
predictions <- ifelse(predict(model, test_data, type = "response") > 0.5, 1, 0)
confusion_matrix <- table(Actual = test_data$is_setosa, Predicted = predictions)
print(confusion_matrix)

# Question 48: AirQuality Analysis
mean_temp <- mean(airquality$Temp, na.rm = TRUE)
print(mean_temp)
print(head(airquality, 5))
subset_airquality <- airquality[, !names(airquality) %in% c("Temp", "Wind")]
print(head(subset_airquality))
coldest_day <- airquality[which.min(airquality$Temp), c("Month", "Day", "Temp")]
print(coldest_day)
windy_days <- sum(airquality$Wind > 17, na.rm = TRUE)
print(windy_days)

# Question 49: Multi-Regression Model for Chicken Weight
data("ChickWeight")
model <- lm(weight ~ Time + Diet, data = ChickWeight)
print(summary(model))
predicted_weight <- predict(model, newdata = data.frame(Time = 10, Diet = factor(1)))
print(predicted_weight)

# Question 50: Titanic Dataset Visualizations
data("Titanic")
titanic_df <- as.data.frame(Titanic)
barplot(tapply(titanic_df$Freq, titanic_df$Class, sum), 
        main = "Passengers by Class", 
        xlab = "Class", 
        ylab = "Count", 
        col = rainbow(4))

# Question 51: Quartiles and Box Plot
data_values <- c(6, 47, 49, 15, 43, 41, 7, 39, 43, 41, 36)
print(quantile(data_values))
boxplot(data_values, main = "Boxplot of Data Values")

# Question 52: Read and Analyze CSV File (using built-in dataset as example)
# Since we don't have "input.csv", we'll use mtcars as an example
input_data <- mtcars
print(max(input_data$mpg, na.rm = TRUE))
print(input_data[which.max(input_data$mpg), ])
# For Department == "IT" example, we'll use cyl == 6 as substitute
print(subset(input_data, cyl == 6))
print(subset(input_data, cyl == 6 & mpg > 20))

# Question 53: Merging Student Data Frames
student_info <- data.frame(StudentID = c(1, 2, 3), Name = c("A", "B", "C"))
student_scores <- data.frame(StudentID = c(1, 2, 3), 
                             MathScore = c(90, 85, 88), 
                             ScienceScore = c(80, 89, 91), 
                             EnglishScore = c(85, 87, 82))
merged_df <- merge(student_info, student_scores, by = "StudentID")
print(merged_df)

# Question 55: Product Data Frame and Average Price
product_data <- data.frame(Name = c("ProductA", "ProductB", "ProductC"), 
                           Price = c(100, 200, 150), 
                           Quantity = c(10, 5, 20))
print(mean(product_data$Price))

# Question 56: Merging Customer and Purchase Data
customer_info <- data.frame(CustomerID = c(1, 2, 3), 
                            Name = c("Alice", "Bob", "Charlie"))
purchase_history <- data.frame(CustomerID = c(1, 2, 3), 
                               Purchase = c(500, 600, 700))
merged_customers <- merge(customer_info, purchase_history, by = "CustomerID")
print(merged_customers)

# Question 57: Sales Regression Model
sales_data <- data.frame(Spends = c(1000, 4000, 5000, 4500, 3000, 4000), 
                         Sales = c(991, 1440, 4875, 4324, 5004, 4347))
sales_model <- lm(Sales ~ Spends, data = sales_data)
print(summary(sales_model))
predicted_sales <- predict(sales_model, newdata = data.frame(Spends = 5000))
print(predicted_sales)

# Question 58: Height-Weight Regression
heights <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
weights <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
height_weight_model <- lm(weights ~ heights)
print(summary(height_weight_model))
predicted_weight <- predict(height_weight_model, newdata = data.frame(heights = 170))
print(predicted_weight)

# Question 59: Salary Distribution Analysis (using mtcars as example)
mean_salary <- mean(mtcars$mpg, na.rm = TRUE)
median_salary <- median(mtcars$mpg, na.rm = TRUE)
print(mean_salary)
print(median_salary)

# Question 60: Univariate EDA on Daily Temperatures
daily_temps <- c(30, 32, 29, 28, 31, 35, 34, 33, 29, 30, 31, 32, 30, 28, 29, 27, 26, 25, 28, 29, 30, 31, 33, 32, 31, 30, 28, 29, 27, 26)
mean_temp <- mean(daily_temps)
median_temp <- median(daily_temps)
range_temp <- range(daily_temps)
sd_temp <- sd(daily_temps)
print(mean_temp)
print(median_temp)
print(range_temp)
print(sd_temp)

# 61. Mean, Median, Mode of mpg in mtcars
library(dplyr)
library(modeest)
data(mtcars)
mpg_mean   <- mean(mtcars$mpg)
mpg_median <- median(mtcars$mpg)
mpg_mode   <- mfv(mtcars$mpg)  # mfv() from modeest package returns the most frequent value
print(paste("Mean mpg:", mpg_mean))
print(paste("Median mpg:", mpg_median))
print(paste("Mode mpg:", mpg_mode))

# 62. ChickWeight dataset analysis
library(dplyr)
data(ChickWeight)
sd_weight    <- sd(ChickWeight$weight)
diet_counts  <- table(ChickWeight$Diet)
heaviest     <- ChickWeight[which.max(ChickWeight$weight), ]
time_counts  <- table(ChickWeight$Time)
print(paste("SD of Weight:", sd_weight))
print(diet_counts)
print("Heaviest Chicken Record:")
print(heaviest)
print(time_counts)

# 63. First and third quartiles of Sepal.Width in iris
data(iris)
quartiles <- quantile(iris$Sepal.Width, probs = c(0.25, 0.75))
print("Quartiles for Sepal.Width:")
print(quartiles)

# 64. Mean of mpg in mtcars
mpg_mean <- mean(mtcars$mpg)
print(paste("Mean mpg:", mpg_mean))

# 65. Create and read CSV file
df <- data.frame(Name = c("A", "B"), Score = c(90, 85))
write.csv(df, "data.csv", row.names = FALSE)
df_read <- read.csv("data.csv")
print("Contents of data.csv:")
print(df_read)

# 66. First and third quartiles of Sepal.Width in iris (duplicate of 63)
quartiles <- quantile(iris$Sepal.Width, probs = c(0.25, 0.75))
print("Quartiles for Sepal.Width (repeat):")
print(quartiles)

# 67. Data frame with rectangle dimensions and area calculation
calculate_area <- function(l, w) {
  if (is.na(l)) l <- 5
  if (is.na(w)) w <- 10
  l * w
}
rectangles <- data.frame(length = c(NA, 7, 8),
                         width  = c(4, 5, NA))
rectangles$area <- mapply(calculate_area, rectangles$length, rectangles$width)
print(rectangles)

# 68. Area of rectangles with plot
library(ggplot2)
lengths <- 1:10
widths  <- 1:10
areas   <- outer(lengths, widths, "*")
grid_df <- expand.grid(length = lengths, width = widths)
grid_df$area <- as.vector(areas)
ggplot(grid_df, aes(x = length, y = width, fill = area)) +
  geom_tile() +
  scale_fill_gradient(low = "lightblue", high = "red") +
  labs(title = "Area of Rectangles (Length vs Width)", x = "Length", y = "Width")

# 69. Variability measures for test scores
scores <- c(85, 90, 78, 92, 88, 76, 95, 89, 84, 91, 87, 82, 90, 93, 88, 85, 77, 94, 80, 79)
min_score    <- min(scores)
max_score    <- max(scores)
score_range  <- range(scores)
variance_val <- var(scores)
sd_val       <- sd(scores)
print(paste("Minimum:", min_score))
print(paste("Maximum:", max_score))
print("Range:")
print(score_range)
print(paste("Variance:", variance_val))
print(paste("Standard Deviation:", sd_val))

# 70. Covariance and correlation between advertising expenditure and sales revenue
advertising <- c(1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500)
sales       <- c(15000, 18000, 21000, 24000, 27000, 30000, 33000, 36000, 39000, 42000)
cov_val <- cov(advertising, sales)
cor_val <- cor(advertising, sales)
print(paste("Covariance:", cov_val))
print(paste("Correlation:", cor_val))

# 71. Covariance and correlation between stock returns
stock_x <- c(1.2, 2.3, 3.1, 4.5, 5.6)
stock_y <- c(2.1, 3.5, 2.9, 5.2, 6.3)
cov_stock <- cov(stock_x, stock_y)
cor_stock <- cor(stock_x, stock_y)
print(paste("Covariance (stocks):", cov_stock))
print(paste("Correlation (stocks):", cor_stock))

# 72. Summary using dplyr on performance scores
library(dplyr)
library(modeest)
scores_df <- data.frame(scores = scores)
summary_stats <- scores_df %>%
  summarize(mean = mean(scores),
            median = median(scores),
            mode = mfv(scores),
            min = min(scores),
            max = max(scores),
            range = max(scores) - min(scores),
            variance = var(scores),
            sd = sd(scores))
print("Summary Statistics for Performance Scores:")
print(summary_stats)

# 73. Quartiles and boxplot for exam scores
boxplot(scores, main = "Boxplot of Exam Scores", ylab = "Scores", col = "lightblue")

# 74. EDA on patients' ages and blood pressure
library(e1071)
patients <- data.frame(Age = c(30, 45, 60, 75, 50),
                       BP  = c(120, 130, 140, 135, 125))
age_mean     <- mean(patients$Age)
age_median   <- median(patients$Age)
age_mode     <- mfv(patients$Age)
age_sd       <- sd(patients$Age)
age_skewness <- skewness(patients$Age)
age_kurtosis <- kurtosis(patients$Age)
bp_mean     <- mean(patients$BP)
bp_median   <- median(patients$BP)
bp_mode     <- mfv(patients$BP)
bp_sd       <- sd(patients$BP)
bp_skewness <- skewness(patients$BP)
bp_kurtosis <- kurtosis(patients$BP)
print(paste("Age - Mean:", age_mean, "Median:", age_median, "Mode:", age_mode))
print(paste("Age - SD:", age_sd, "Skewness:", age_skewness, "Kurtosis:", age_kurtosis))
print(paste("BP - Mean:", bp_mean, "Median:", bp_median, "Mode:", bp_mode))
print(paste("BP - SD:", bp_sd, "Skewness:", bp_skewness, "Kurtosis:", bp_kurtosis))

# 75. Covariance and correlation between products sold and prices
products_sold <- c(10, 15, 20, 25, 30)
prices        <- c(50, 55, 60, 65, 70)
cov_products <- cov(products_sold, prices)
cor_products <- cor(products_sold, prices)
print(paste("Covariance (Products Sold vs Prices):", cov_products))
print(paste("Correlation (Products Sold vs Prices):", cor_products))

# 76. Data visualization: histogram, boxplot, scatter plot
hist(scores, main = "Histogram of Scores", xlab = "Scores", col = "lightgreen")
boxplot(scores, main = "Boxplot of Scores", ylab = "Scores", col = "lightblue")
plot(advertising, sales, main = "Scatter Plot: Advertising vs Sales", 
     xlab = "Advertising Expenditure", ylab = "Sales Revenue", pch = 19, col = "darkred")

# 77. Covariance and correlation with scatter plot and trend line
library(ggplot2)
adv_sales_df <- data.frame(advertising = advertising, sales = sales)
ggplot(adv_sales_df, aes(x = advertising, y = sales)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Advertising vs Sales with Trend Line", x = "Advertising Expenditure", y = "Sales Revenue")

# 78. Scatter plot with trend line for stock returns
library(ggplot2)
stock_df <- data.frame(stock_x = stock_x, stock_y = stock_y)
ggplot(stock_df, aes(x = stock_x, y = stock_y)) +
  geom_point(color = "darkgreen") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Stock X vs Stock Y Returns", x = "Stock X Returns", y = "Stock Y Returns")

# 79. Correlation matrix and heatmap for mtcars variables
library(ggplot2)
library(reshape2)
cor_matrix <- cor(mtcars)
melted_corr <- melt(cor_matrix)
ggplot(melted_corr, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlation") +
  theme_minimal() +
  labs(title = "Correlation Heatmap for mtcars")

# 80. Pair plot (scatterplot matrix) for mtcars
library(GGally)
ggpairs(mtcars[, c("mpg", "disp", "hp", "wt")], title = "Scatterplot Matrix for mtcars Variables")

# 81. Create a Data Frame and Box Plot
scores <- data.frame(
  Class = rep(paste('Class', 1:5), each = 10),
  Score = c(rnorm(10, 70, 10), rnorm(10, 75, 10), rnorm(10, 80, 10), rnorm(10, 85, 10), rnorm(10, 90, 10))
)
library(ggplot2)
ggplot(scores, aes(x = Class, y = Score)) + geom_boxplot()

# 82. Scatter Plot with Regression Line
data <- data.frame(Experience = rnorm(100, 5, 2), Salary = rnorm(100, 50000, 10000))
ggplot(data, aes(x = Experience, y = Salary)) + geom_point() + geom_smooth(method = "lm")

# 83. Histogram
data <- rnorm(1000)
hist(data, breaks = 20, col = "blue")

# 84. Legend in Plot
plot(1:10, col = "red", pch = 16, main = "Legend Example")
legend("topright", legend = "Data Points", col = "red", pch = 16)

# 85. Histogram by Group (Lattice)
library(lattice)
data <- data.frame(Group = rep(c("A", "B"), each = 50), Value = rnorm(100))
histogram(~Value | Group, data = data, layout = c(2, 1))

# 86. Density Plot
ggplot(data, aes(x = Value, fill = Group)) + geom_density(alpha = 0.5)

# 87. Interactive Bar Plot (Plotly)
library(plotly)
p <- ggplot(mtcars, aes(factor(cyl))) + geom_bar()
ggplotly(p)

# 88. Linear Regression (mtcars)
model <- lm(mpg ~ wt, data = mtcars)
ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() + geom_smooth(method = "lm")

# 89. Scatter Plot (Iris)
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + geom_point()

# 90. Multiple Regression (House Prices)
houses <- data.frame(area = rnorm(50, 1500, 200), bedrooms = sample(1:5, 50, replace = TRUE), price = rnorm(50, 300000, 50000))
model <- lm(price ~ area + bedrooms, data = houses)
summary(model)

# 91. Histogram (Ages)
library(ggplot2)
ages <- data.frame(Age = rnorm(100, 35, 10))
ggplot(ages, aes(x = Age)) + geom_histogram(binwidth = 5, fill = "blue")

# 92. Pie Chart (Iris)
iris_counts <- table(iris$Species)
pie(iris_counts, labels = names(iris_counts))

# 93. ChickWeight Analysis
data(ChickWeight)
hist(ChickWeight$weight)
sum(is.na(ChickWeight))
median(ChickWeight$weight)


# 95. AirQuality Dataset
data(airquality)
airquality <- airquality[order(airquality$Ozone, airquality$Solar.R), ]
airquality <- subset(airquality, select = -c(Solar.R, Wind))

# 96. Titanic Dataset
library(ggplot2)
data(Titanic)
titanic_df <- as.data.frame(Titanic)
ggplot(titanic_df, aes(x = Class, fill = Survived)) + geom_bar()

# 97. Salary Stats
salaries <- data.frame(Salary = rnorm(100, 50000, 10000))
mean(salaries$Salary)
median(salaries$Salary)

# 98. AirQuality Processing
data(airquality)  
is.data.frame(airquality)
airquality <- airquality[order(airquality$Ozone, airquality$Solar.R, na.last = TRUE), ]
airquality <- subset(airquality, select = -c(Solar.R, Wind))
head(airquality)

# 99. Line and Bar Chart
plot(pressure, type = "l")
barplot(pressure$pressure, names.arg = pressure$temperature)

# 100. Multiple Regression (mtcars)
model <- lm(mpg ~ wt + hp, data = mtcars)
summary(model)



-------------------------------- SAMPLE SETS --------------------------------------
SET 1

# 1. Basic arithmetic operations simulation
simulate_arithmetic <- function() {
  test_cases <- list(
    c(1e308, 1e308), c(1e-323, 1e-323), c(0, 0),
    c(Inf, Inf), c(NA, 5), c(1.23456789, 0.00000001)
  )
  operations <- c("+", "-", "*", "/", "%%", "^")
  
  for(op in operations) {
    cat("Operation:", op, "\n")
    for(case in test_cases) {
      a <- case[1]; b <- case[2]
      r_result <- eval(parse(text = paste("a", op, "b")))
      cat(sprintf("%g %s %g = %s\n", a, op, b, 
                 ifelse(is.na(r_result), "NA", format(r_result, scientific = FALSE))))
    }
    cat("\n")
  }
}
simulate_arithmetic()

# 2. Airquality dataset analysis
data(airquality)
summary(airquality)
library(reshape2)
aq_long <- melt(airquality, id.vars = c("Month", "Day"))
head(aq_long)

# 3. Iris classification model
library(nnet)
set.seed(123)
train_indices <- sample(1:nrow(iris), 0.8 * nrow(iris))
model <- multinom(Species ~ Petal.Width + Petal.Length, data = iris[train_indices,])
test_pred <- predict(model, newdata = iris[-train_indices,])
table(test_pred, iris[-train_indices,]$Species)

# 4. Multidimensional array
my_array <- array(1:24, dim = c(4, 3, 2),
                 dimnames = list(
                   c("Row1", "Row2", "Row3", "Row4"),
                   c("Col1", "Col2", "Col3"),
                   c("Table1", "Table2")
                 ))
my_array

------------------------------------------------------------------------------------------------------------------------
SET 2

# 1. Student performance data frame
student_data <- data.frame(
  StudentID = 1:10,
  Name = c("Alice", "Bob", "Charlie", "David", "Eve", "Frank", "Grace", "Heidi", "Ivan", "Judy"),
  Score = c(85, 72, 91, 63, 77, 89, 68, 95, 81, 59),
  Attempts = c(1, 2, 1, 3, 2, 1, 2, 1, 3, 2),
  Qualified = c(TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE)
)
student_data

# 2. List with mixed data types
my_list <- list(
  numeric_vector = 1:10,
  character_vector = letters[1:5],
  matrix = matrix(1:9, nrow = 3),
  custom_function = function(x) x^2
)
str(my_list)

# 3. USArrests analysis
data(USArrests)
summary(USArrests)
USArrests[which.max(USArrests$Rape),]
cor(USArrests)
USArrests[USArrests$Assault > median(USArrests$Assault),]

# 4. Sales data analysis (using data frame instead of CSV)
sales_data <- data.frame(
  OrderID = 1001:1005,
  Product = c("Laptop", "Mouse", "Keyboard", "Monitor", "Headphones"),
  Quantity = c(1, 2, 1, 1, 3),
  UnitPrice = c(999.99, 19.99, 49.99, 199.99, 79.99)
)
head(sales_data)
str(sales_data)
--------------------------------------------------------------------------------------------------------
SET 3

# 1. Vectors of different types
numeric_vec <- c(12.5, 9.0, 16.5, 12.0, 9.0)
character_vec <- c("Anastasia", "Dima", "Katherine", "James", "Emily")
logical_vec <- c(TRUE, FALSE, TRUE, FALSE, FALSE)
numeric_vec
character_vec
logical_vec

# 2. Data frame operations
exam_data <- data.frame(
  name = c('Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'),
  score = c(12.5, 9, 16.5, 12, 9, 20, 14.5, 13.5, 8, 19),
  attempts = c(1, 3, 2, 3, 2, 3, 1, 1, 2, 1),
  qualify = c('yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes'),
  stringsAsFactors = FALSE
)

# Operations
exam_data[c(3,5), c(1,3)]
exam_data$country <- c("USA","USA","USA","USA","UK","USA","USA","India","USA","USA")
new_rows <- data.frame(
  name = c('Robert', 'Sophia'),
  score = c(10.5, 9),
  attempts = c(1, 3),
  qualify = c('yes', 'no'),
  country = c('USA', 'UK'),
  stringsAsFactors = FALSE
)
rbind(exam_data, new_rows)
exam_data[order(exam_data$name, exam_data$score),]

# 3. Women's height
data(women)
women$height_cat <- cut(women$height, 
                       breaks = c(58, 62, 66, 70, 72),
                       labels = c("Short", "Medium-Short", "Medium-Tall", "Tall"))
table(women$height_cat)
barplot(table(women$height_cat))

# 4. Matrices
matrix(1:20, nrow = 5, ncol = 4, byrow = TRUE)  
matrix(c(9, 2, 7, 4, 5, 6, 3, 8, 1), nrow = 3,
       dimnames = list(c("Row_A","Row_B","Row_C"), c("Col_1","Col_2","Col_3")))

---------------------------------------------------------------------------------------------------------

SET 4
# 1. Multidimensional array
product_sales <- array(1:24, dim = c(4, 3, 2),
                      dimnames = list(
                        c("Widget", "Gadget", "Thingy", "Doodad"),
                        c("North", "South", "West"), 
                        c("Q1", "Q2")
                      ))
print("--- Array Output ---")
print(product_sales)

# 2. Airquality manipulation
data(airquality)
air_ordered <- airquality[order(airquality$Month, airquality$Day),]
air_reduced <- air_ordered[, !names(air_ordered) %in% c("Solar.R", "Wind")]
print("\n--- Ordered Airquality Data ---")
print(head(air_ordered))
print("\n--- Reduced Airquality Data ---")
print(head(air_reduced))

# 3. ChickWeight analysis
data(ChickWeight)
library(reshape2)
chick_melt <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))
chick_cast_mean <- dcast(ChickWeight, Diet ~ ., fun.aggregate = mean, value.var = "weight")
print("\n--- Melted ChickWeight Data ---")
print(head(chick_melt))
print("\n--- Mean Weight by Diet ---")
print(chick_cast_mean)

# 4. Iris classification
library(nnet)
set.seed(42)
train_indices <- sample(1:nrow(iris), 0.8 * nrow(iris))
model <- multinom(Species ~ Petal.Width + Petal.Length, data = iris[train_indices,])
test_pred <- predict(model, newdata = iris[-train_indices,])
conf_matrix <- table(Predicted = test_pred, Actual = iris[-train_indices, "Species"])
print("\n--- Confusion Matrix ---")
print(conf_matrix)
print("\n--- Model Summary ---")
print(summary(model))

-----------------------------------------------------------------------------------------------------------

SET 5
# 1. Dynamic factor subsetting
set.seed(123)
my_factor <- factor(sample(LETTERS[1:10], 50, replace = TRUE))
subset_factor <- function(fct, levels_to_keep) droplevels(fct[fct %in% levels_to_keep])
subset_factor(my_factor, c("A", "D", "F"))

# 2. Employee data analysis (using data frame)
emp_data <- data.frame(
  id = 1:5,
  name = c("John", "Lisa", "Mark", "Linda", "James"),
  salary = c(700, 800, 600, 900, 750),
  department = c("IT", "Operations", "IT", "HR", "IT"),
  start_date = as.Date(c("2014-05-24", "2013-08-19", "2015-02-28", "2012-11-01", "2016-06-17"))
)
max(emp_data$salary)
emp_data[emp_data$salary == max(emp_data$salary),]
subset(emp_data, department == "IT")
subset(emp_data, department == "IT" & salary > 600)
subset(emp_data, start_date >= as.Date("2014-01-01"))

# 3. Random vector analysis
set.seed(42)
random_vec <- sample(-50:50, 10)
random_vec
abs(random_vec)
scales::rescale(random_vec, to = c(0, 100))

# 4. FizzBuzz implementation
result <- sapply(1:100, function(x) {
  if (x %% 15 == 0) return("FizzBuzz")
  if (x %% 3 == 0) return("Fizz")
  if (x %% 5 == 0) return("Buzz")
  return(x)
})
head(result, 20)

------------------------------------------------------------------------------------------------------------------------

#SAMPLE 6
1.arithmetic
# Define a function with default arguments returning a complex object
perform_operations <- function(x, y = 5) {
  sum_result <- x + y
  product_result <- x * y
  power_result <- x ^ y
  results_list <- list(
    sum = sum_result,
    product = product_result,
    power = power_result,
    metadata = list(
      input_x = x,
      input_y = y
    )
  )
  return(results_list)
}

# Create a sample vector
numbers_vector <- c(2, 7, 12, 5, 9, 14)

# Iterate through the vector using for loop
for (number in numbers_vector) {
  # Check if number is even using if-else statement
  if (number %% 2 == 0) {
    cat("Processing even number:", number, "\n")
    # Use default y value for even numbers
    operation_results <- perform_operations(number)
  } else {
    cat("Processing odd number:", number, "\n")
    # Use custom y value for odd numbers
    operation_results <- perform_operations(number, y = 3)
  }
  
  # Print the results
  print(operation_results)
  cat("\n")  # Add spacing between iterations
}
2.Titanic Dataset Analysis
# Load required packages
library(ggplot2)
library(datasets)
data("Titanic")

# Convert Titanic table to dataframe
titanic_df <- as.data.frame(Titanic)

# 2a. Bar chart of Survival by Class
ggplot(titanic_df, aes(x = Class, weight = Freq, fill = Survived)) +
  geom_bar(position = "dodge") +
  labs(title = "Survival Count by Passenger Class", y = "Count")

# 2b. Modified plot with Gender
ggplot(titanic_df, aes(x = Class, weight = Freq, fill = Survived)) +
  geom_bar(position = "dodge") +
  facet_wrap(~ Sex) +
  labs(title = "Survival Count by Class and Gender", y = "Count")

# 2c. Age Distribution Histogram
# Note: Actual Titanic dataset doesn't contain individual ages, but we can use another version
# Install and load proper dataset if needed
# install.packages("titanic")
library(titanic)
data("titanic_train")

ggplot(titanic_train, aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  labs(title = "Age Distribution of Passengers", x = "Age", y = "Count")
3. Combine Arrays with Interleaved Rows
interleave_arrays <- function(...) {
  arrays <- list(...)
  max_rows <- max(sapply(arrays, nrow))
  result <- NULL
  
  for (i in 1:max_rows) {
    for (arr in arrays) {
      if (i <= nrow(arr)) {
        result <- rbind(result, arr[i, ])
      }
    }
  }
  return(result)
}

# Example usage:
array1 <- matrix(1:4, nrow = 2)
array2 <- matrix(5:8, nrow = 2)
array3 <- matrix(9:12, nrow = 2)
combined <- interleave_arrays(array1, array2, array3)
print(combined)
4.Sales Prediction
sales_data <- data.frame(
  Month = 1:12,
  Spends = c(1000, 4000, 5000, 4500, 3000, 4000, 9000, 
             11000, 15000, 12000, 7000, 3000),
  Sales = c(9914, 40487, 54324, 50044, 34719, 42551, 94871,
            118914, 158484, 131348, 78504, 36284)
)

# 4b. Create regression model
model <- lm(Sales ~ Spends, data = sales_data)
summary(model)

# 4c. Predict Sales for Spend=13500
new_data <- data.frame(Spends = 13500)
predicted_sales <- predict(model, newdata = new_data)

cat("Predicted Sales for $13,500 Spend: $", round(predicted_sales, 2))
------------------------------------------------------------------------------------------------------------------------

#SAMPLE 7
1. Array of Matrices and Element Access
# Create vectors
vec1 <- c(1:9)
vec2 <- c(10:18)

# Create array of two 3x3 matricesA <- c(1:9)  # Modified to 9 elements for valid 3x3 matrix
B <- c(10:18) # Modified to 9 elements for valid 3x3 matrix

# Create 3x3x2 array
three_d_array <- array(c(A, B), dim = c(3, 3, 2))
print(three_d_array)
matrix_array <- array(c(vec1, vec2), dim = c(3, 3, 2))

# Print required elements
cat("Second row of second matrix:\n")
print(matrix_array[2,,2])

cat("\nElement at 3rd row, 3rd column of first matrix:", 
    matrix_array[3,3,1])
2. Combine Vectors into 3D Array
A <- c(1:9)  # Modified to 9 elements for valid 3x3 matrix
B <- c(10:18) # Modified to 9 elements for valid 3x3 matrix

# Create 3x3x2 array
three_d_array <- array(c(A, B), dim = c(3, 3, 2))
print(three_d_array)
3. airquality Dataset Analysis
data(airquality)

# i. Manual mean calculation
temp_sum <- 0
count <- 0
for (t in airquality$Temp) {
  if (!is.na(t)) {
    temp_sum <- temp_sum + t
    count <- count + 1
  }
}
cat("Manual mean temperature:", temp_sum/count, "\n")

# ii. First 5 rows
first_five <- head(airquality, 5)
print(first_five)

# iii. Exclude Temp and Wind
subset_data <- airquality[, !(names(airquality) %in% c("Temp", "Wind"))]
print(head(subset_data))
4. Flexible Data Sorting with NA Handling
flexible_sort <- function(df, sort_cols, na_position = "last") {
  df$na_flag <- ifelse(is.na(df$score), 1, 0)
  
  if(na_position == "last") {
    df <- df[order(df$na_flag, df[[sort_cols[1]], df[[sort_cols[2]]]), ]
  } else if(na_position == "first") {
    df <- df[order(-df$na_flag, df[[sort_cols[1]], df[[sort_cols[2]]]), ]
  }
  
  df$na_flag <- NULL
  return(df)
}

# Example usage:
demo_df <- data.frame(
  name = c("Bob", "Alice", "Charlie", "David"),
  score = c(88, NA, 92, 78)
)

# Default sorting (NAs last)
sorted_default <- flexible_sort(demo_df, c("name", "score"))
print(sorted_default)

# Custom sorting (NAs first)
sorted_custom <- flexible_sort(demo_df, c("name", "score"), "first")
print(sorted_custom)
------------------------------------------------------------------------------------------------------------------------
SAMPLE 8
1.# Create an empty plot with custom axis labels
plot(1, type = "n", 
     xlim = c(0, 12), ylim = c(0, 160000),
     xlab = expression(paste("Month (", alpha, "-scale)")),
     ylab = expression(paste("Sales (₹ ", 10^3, ")")),
     main = "Customized Empty Plot")

# Add axis ticks and labels
axis(1, at = 1:12, labels = month.abb[1:12])
axis(2, at = seq(0, 160000, by = 20000), 
     labels = format(seq(0, 160000, by = 20000), las = 2)
2.# Create a vector of values and specify dimensions
values <- c(1:24)
dimensions <- c(3, 4, 2)  # 3 rows, 4 columns, 2 matrices

# Define dimension names
dim_names <- list(
  Rows = c("Row1", "Row2", "Row3"),
  Columns = c("Col1", "Col2", "Col3", "Col4"),
  Matrices = c("Matrix1", "Matrix2")
)

# Create named array
named_array <- array(values, dim = dimensions, dimnames = dim_names)
print(named_array)
3.library(reshape2)
data(airquality)

# i. Summary Statistics
summary_stats <- summary(airquality)
cat("Summary Statistics:\n")
print(summary_stats)

# ii. Melt into long format
melted_data <- melt(airquality, id.vars = c("Month", "Day"))
cat("\nMelted Data (Long Format):\n")
print(head(melted_data))

# iii. Cast by Month and Day
casted_data <- dcast(melted_data, Month + Day ~ variable)
cat("\nCasted Data (Wide Format):\n")
print(head(casted_data))

# iv. Monthly Averages
monthly_avg <- dcast(melted_data, Month ~ variable, fun.aggregate = mean, na.rm = TRUE)
cat("\nMonthly Averages:\n")
print(monthly_avg)
4.# a. Create data frame
sales_df <- data.frame(
  Month = 1:12,
  Spends = c(1000, 4000, 5000, 4500, 3000, 4000, 9000, 11000, 15000, 12000, 7000, 3000),
  Sales = c(9914, 40487, 54324, 50044, 34719, 42551, 94871, 118914, 158484, 131348, 78504, 36284)
)

# b. Regression model
model <- lm(Sales ~ Spends, data = sales_df)
cat("Regression Model Summary:\n")
print(summary(model))

# c. Predict for Spend=13500
new_data <- data.frame(Spends = 13500)
predicted_sales <- predict(model, newdata = new_data)
cat("\nPredicted Sales for ₹13,500 Spend: ₹", round(predicted_sales, 2))
--------------------------------------------------------------------------------------
SAMPLE 9
1.data("USArrests")

# (i) a. Summary and Statistical Features
cat("(i) a. Dataset Summary:\n")
print(str(USArrests))  # Structure
cat("\nNumber of records:", nrow(USArrests))
cat("\nNumber of features:", ncol(USArrests))
cat("\nFeature types:\n")
print(sapply(USArrests, class))
cat("\nStatistical summary:\n")
print(summary(USArrests))

# (i) b. State with Largest Rape Arrests
max_rape_state <- rownames(USArrests)[which.max(USArrests$Rape)]
cat("\n(i) b. State with highest rape arrests:", max_rape_state)

# (i) c. States with Max/Min Murder Rates
max_murder_state <- rownames(USArrests)[which.max(USArrests$Murder)]
min_murder_state <- rownames(USArrests)[which.min(USArrests$Murder)]
cat("\n(i) c. States:\nMax Murder:", max_murder_state, "\nMin Murder:", min_murder_state)

# (ii) a. Correlation Matrix
cat("\n\n(ii) a. Correlation Matrix:\n")
print(cor(USArrests))

# (ii) b. Assaults Above Median
assault_median <- median(USArrests$Assault)
high_assault_states <- rownames(USArrests)[USArrests$Assault > assault_median]
cat("\n(ii) b. States with assault > median:\n")
print(high_assault_states)

# (ii) c. Bottom 25% of Murder
murder_25 <- quantile(USArrests$Murder, 0.25)
bottom_murder_states <- rownames(USArrests)[USArrests$Murder < murder_25]
cat("\n(ii) c. States in bottom 25% of murder:\n")
print(bottom_murder_states)

# (iii) a. Histogram and Density Plot
hist(USArrests$Murder, main = "Murder Arrests Histogram", col = "skyblue", xlab = "Murder Rate")
lines(density(USArrests$Murder), col = "red", lwd = 2)

# (iii) b. Scatter Plot with Color Gradient
plot(USArrests$UrbanPop, USArrests$Murder, 
     col = colorRampPalette(c("blue", "red"))(100)[cut(USArrests$Assault, 100)],
     pch = 19, xlab = "Urban Population (%)", ylab = "Murder Rate",
     main = "Murder Rate vs Urban Population")

# (iii) c. Bar Graph
barplot(USArrests$Murder, names.arg = rownames(USArrests), las = 2,
        col = "steelblue", main = "Murder Rate by State", cex.names = 0.6)
2.library(nnet)  # For multinomial regression
data("iris")

# Split data
set.seed(123)
train_idx <- sample(1:nrow(iris), 0.8*nrow(iris))
train_data <- iris[train_idx, ]
test_data <- iris[-train_idx, ]

# Model
model <- multinom(Species ~ Petal.Width + Petal.Length, data = train_data)

# Predictions
pred_probs <- predict(model, test_data, type = "prob")
pred_class <- predict(model, test_data)

# Confusion Matrix
conf_matrix <- table(test_data$Species, pred_class)
cat("\nConfusion Matrix:\n")
print(conf_matrix)
3.# Create sample data frame
df <- data.frame(ID = 1:3, Name = c("Alice", "Bob", "Charlie"))

# Save to file
write.csv(df, "data_info.csv", row.names = FALSE)

# Display file info
cat("\nFile Information:\n")
print(file.info("data_info.csv"))
4.data("airquality")

# Check if data frame
cat("Is airquality a data frame?", is.data.frame(airquality), "\n")

# Order by first and second columns
ordered_data <- airquality[order(airquality$Ozone, airquality$Solar.R), ]

# Remove Solar.R and Wind
subset_data <- ordered_data[, !(names(ordered_data) %in% c("Solar.R", "Wind"))]

# Display
cat("\nModified Data Frame:\n")
print(head(subset_data))
--------------------------------------------------------------------------------------
SAMPLE 10
1.# Create vectors
product_names <- c("Laptop", "Mouse", "Keyboard", "Monitor", "Headset")
prices <- c(1200, 50, 80, 300, 150)
quantities <- c(15, 100, 45, 25, 30)

# Create data frame
product_data <- data.frame(
  Name = product_names,
  Price = prices,
  Quantity = quantities
)

# Access average price
average_price <- mean(product_data$Price)
cat("Average Price:", average_price, "\n")

# Output data frame
print(product_data)
2.# Create data frame
employee_data <- data.frame(
  ID = c(101, 102, 103, 104),
  Name = c("Alice", "Bob", "Charlie", "David"),
  Age = c(28, 34, 45, 32),
  Salary = c(60000, 75000, 90000, 65000)
)

# Add new column (Bonus)
employee_data$Bonus <- employee_data$Salary * 0.05

# Filter rows (Age > 30)
filtered_data <- subset(employee_data, Age > 30)

# Sort by Salary
sorted_data <- employee_data[order(employee_data$Salary, decreasing = TRUE), ]

# Print results
cat("\nFiltered Data (Age > 30):\n")
print(filtered_data)
cat("\nSorted Data (High to Low Salary):\n")
print(sorted_data)
3.# Create numeric vector
numeric_vector <- c(3, 7, 12, 5, 9, 2, 15)

# Logical conditions
condition <- (numeric_vector > 5) & (numeric_vector < 10)
filtered_values <- numeric_vector[condition]

# Print results
cat("Logical Vector (5 < x < 10):\n", condition, "\n")
cat("Filtered Values:\n", filtered_values, "\n")
4.# Recursive Fibonacci function
fibonacci <- function(n) {
  if (n <= 1) {
    return(n)
  } else {
    return(fibonacci(n-1) + fibonacci(n-2))
  }
}

# User input and output
n<-5
cat("The", n, "th Fibonacci number is:", fibonacci(n), "\n")

---------------------------------------------------------------------------------------------------------------------------
##################################################################################
Sample-11
#1 Iris dataset petals
library(nnet)
library(ggplot2)
data(iris)
set.seed(123)
train_idx <- sample(1:nrow(iris), 0.8*nrow(iris))
train <- iris[train_idx,]; test <- iris[-train_idx,]
model <- multinom(Species ~ Petal.Width + Petal.Length, data = train)
pred <- predict(model, test)
probs <- predict(model, test, type = "probs")
cm <- table(Predicted = pred, Actual = test$Species)

accuracy <- sum(diag(cm))/sum(cm)
metrics <- data.frame(
  Precision = diag(cm)/rowSums(cm),
  Recall = diag(cm)/colSums(cm)
)
metrics$F1 <- 2*(metrics$Precision*metrics$Recall)/(metrics$Precision+metrics$Recall)

ggplot(data.frame(Actual = test$Species, Predicted = pred), 
       aes(x = Actual, fill = Actual == Predicted)) +
  geom_bar() +
  scale_fill_manual(values = c("red", "green")) +
  ggtitle(paste("Accuracy:", round(accuracy, 2)*100, "%"))

ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) +
  geom_point() + 
  stat_ellipse() +
  ggtitle("Decision Boundaries")#1 Iris dataset petals
library(nnet)
library(ggplot2)
data(iris)
set.seed(123)
train_idx <- sample(1:nrow(iris), 0.8*nrow(iris))
train <- iris[train_idx,]; test <- iris[-train_idx,]
model <- multinom(Species ~ Petal.Width + Petal.Length, data = train)
pred <- predict(model, test)
probs <- predict(model, test, type = "probs")
cm <- table(Predicted = pred, Actual = test$Species)

accuracy <- sum(diag(cm))/sum(cm)
metrics <- data.frame(
  Precision = diag(cm)/rowSums(cm),
  Recall = diag(cm)/colSums(cm)
)
metrics$F1 <- 2*(metrics$Precision*metrics$Recall)/(metrics$Precision+metrics$Recall)

ggplot(data.frame(Actual = test$Species, Predicted = pred), 
       aes(x = Actual, fill = Actual == Predicted)) +
  geom_bar() +
  scale_fill_manual(values = c("red", "green")) +
  ggtitle(paste("Accuracy:", round(accuracy, 2)*100, "%"))

ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) +
  geom_point() + 
  stat_ellipse() +
  ggtitle("Decision Boundaries")




# 2. Air Quality Data (Base R)
# i) Long format conversion
long_aq <- data.frame(
  Month = rep(airquality$Month, 4),
  Day = rep(airquality$Day, 4),
  Variable = rep(c("Ozone","Solar.R","Wind","Temp"), each = nrow(airquality)),
  Value = c(airquality$Ozone, airquality$Solar.R, airquality$Wind, airquality$Temp)
)
head(long_aq, 8) # Show first 8 rows

# ii) Monthly averages
monthly_avg <- aggregate(cbind(Ozone, Solar.R, Wind, Temp) ~ Month, 
                       data = airquality, 
                       FUN = mean, 
                       na.rm = TRUE)
print(monthly_avg)

# 3. Women's Height Categories
data(women)
women$height_cat <- cut(women$height,
                       breaks = c(58, 62, 67, 72),
                       labels = c("Short", "Medium", "Tall"))
table(women$height_cat)

# 4. Mixed List
my_list <- list(
  vector = 1:10,
  matrix = matrix(1:9, nrow = 3),
  summary_func = function(x) {
    c(Mean = mean(x), 
      Median = median(x), 
      SD = sd(x))
  }
)

# Test the function
my_list$summary_func(my_list$vector)





#########################################################################################

Sample-12
# Q1: Dynamic Factors
set.seed(123)
fct <- factor(sample(LETTERS[1:5], 20, replace=TRUE))
print(droplevels(fct[fct %in% c("A","C")]))



# Q2: CSV Analysis
data <- data.frame(
  Name = c("John","Mary","Mike"),
  Department = c("IT","HR","IT"),
  Salary = c(65,58,72)
)
write.csv(data, "input.csv", row.names=FALSE)
df <- read.csv("input.csv")
print(df[which.max(df$Salary),])
print(subset(df, Department=="IT" & Salary>60))



# Q3: Random Vector
set.seed(123)
vec <- sample(-50:50, 10)
print(summary(vec))



# Q4: Number Categorization
result <- sapply(1:100, function(x) {
  if(x%%15==0) "Both" else if(x%%3==0) "Three" else if(x%%5==0) "Five" else "None"
})
print(table(result))




#########################################################################################




Sample-13

# Q1: Basic Stats
print(head(airquality, 5))
print(mean(airquality$Temp, na.rm=TRUE))

# Q2: Wind Analysis
print(sum(airquality$Wind>17, na.rm=TRUE))
print(summary(airquality$Wind))

# Q3: Summary & Plot
print(summary(airquality))
hist(airquality$Ozone, main="Ozone Distribution")

# Q4: Regression
clean_aq <- na.omit(airquality)
model <- lm(Ozone ~ Solar.R, data=clean_aq)
print(summary(model))


#########################################################################################


Sample-14
# Q1: Fibonacci
fib <- function(n) ifelse(n<2, n, fib(n-1)+fib(n-2))
print(sapply(0:9, fib))

# Q2: ChickWeight
data(ChickWeight)
print(tail(ChickWeight, 6))

# Q3: Melting/Casting
library(reshape2)
melted <- melt(ChickWeight, id.vars=c("Chick","Time","Diet"))
print(dcast(melted, Diet ~ variable, mean))

# Q4: Regression
ChickWeight$Diet <- factor(ChickWeight$Diet)
model <- lm(weight ~ Time + Diet, data=ChickWeight)
new_data <- data.frame(Time=10, Diet=factor(1))
print(predict(model, new_data))


#########################################################################################

Sample-15

# Q1: Data Frame
students <- data.frame(
  ID = 1:3,
  Name = c("Alice","Bob","Charlie"),
  Score = c(85,92,78),
  Passed = c(TRUE,TRUE,FALSE)
)
print(str(students))

# Q2: Mixed List
my_list <- list(
  vec = 1:3,
  mat = matrix(1:4, ncol=2),
  fun = function(x) mean(x)
)
print(str(my_list))

# Q3: USArrests
data(USArrests)
print(rownames(USArrests)[which.max(USArrests$Rape)])
print(c(Max=rownames(USArrests)[which.max(USArrests$Murder)],
        Min=rownames(USArrests)[which.min(USArrests$Murder)]))

# Q4: Dynamic Factors
set.seed(123)
fct <- factor(sample(LETTERS, 15))
print(droplevels(fct[fct %in% c("A","B","C")]))

------------------------------------------------------------------------------------------------------

#SET 16 
# 1.a. Recursive function to generate Fibonacci sequence
fibonacci <- function(n) {
  if (n <= 0) {
    return(NA)
  } else if (n == 1) {
    return(0)
  } else if (n == 2) {
    return(1)
  } else {
    return(fibonacci(n - 1) + fibonacci(n - 2))
  }
}

# Function to print Fibonacci sequence up to 'num' terms
print_fibonacci <- function(num) {
  fib_sequence <- sapply(1:num, fibonacci)
  cat("Fibonacci sequence:", fib_sequence, "\n")
}

# Call function to print Fibonacci sequence up to 10 terms
print_fibonacci(10)

# 1.b. Sum of natural numbers up to 10 using a loop
sum_natural_numbers <- function(n) {
  sum <- 0
  for (i in 1:n) {
    sum <- sum + i
  }
  return(sum)
}

# Call function to find sum of first 10 natural numbers
cat("Sum of first 10 natural numbers:", sum_natural_numbers(10), "\n")
#-----------------------------------

#2 mean,median,mode
# Given values
c_values <- c(90, 50, 70, 80, 70, 60, 20, 30, 80, 90, 20)

# 2.a. Compute Mean, Median, and Mode
mean_value <- mean(c_values)      # Mean
median_value <- median(c_values)  # Median

# Function to calculate mode
get_mode <- function(x) {
  unique_x <- unique(x)
  freq <- tabulate(match(x, unique_x))
  mode_values <- unique_x[freq == max(freq)]
  return(mode_values)
}

mode_value <- get_mode(c_values)

# Print results
cat("Mean:", mean_value, "\n")
cat("Median:", median_value, "\n")
cat("Mode:", mode_value, "\n")

# 2.b. Find 2nd highest and 3rd lowest value
sorted_values <- sort(unique(c_values))  # Sort unique values

second_highest <- sorted_values[length(sorted_values) - 1] # 2nd highest
third_lowest <- sorted_values[3] # 3rd lowest

cat("2nd Highest Value:", second_highest, "\n")
cat("3rd Lowest Value:", third_lowest, "\n")

#-----------------------------------
#3 mt cars wt vs disp, hp vs mpg ...
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Load mtcars dataset
data(mtcars)

# Convert vs (Engine Shape) and cyl (Cylinders) to factors for better visualization
mtcars$vs <- as.factor(mtcars$vs)
mtcars$cyl <- as.factor(mtcars$cyl)

# 3.a. Weight (wt) vs Displacement (disp) Scatter Plot, Colored by Engine Shape (vs)
ggplot(mtcars, aes(x = wt, y = disp, color = vs)) +
  geom_point(size = 3) +
  labs(title = "Weight vs Displacement",
       x = "Weight (1000 lbs)", 
       y = "Displacement (cu.in.)",
       color = "Engine Shape (vs)") +
  theme_minimal()

# 3.b. Horsepower (hp) vs Mileage (mpg) Scatter Plot, Colored by Engine Shape (vs)
ggplot(mtcars, aes(x = hp, y = mpg, color = vs)) +
  geom_point(size = 3) +
  labs(title = "Horsepower vs Mileage",
       x = "Horsepower (hp)", 
       y = "Miles per Gallon (mpg)",
       color = "Engine Shape (vs)") +
  theme_minimal()

# 3.c. Modify 3.b plot to Separate Columns by Cylinders (cyl)
ggplot(mtcars, aes(x = hp, y = mpg, color = vs)) +
  geom_point(size = 3) +
  facet_wrap(~cyl) +  # Create separate columns based on cylinder count
  labs(title = "Horsepower vs Mileage (Separated by Cylinders)",
       x = "Horsepower (hp)", 
       y = "Miles per Gallon (mpg)",
       color = "Engine Shape (vs)") +
  theme_minimal()

#-----------------------------------

#4 height prediction
# Load necessary library
library(ggplot2)

# Given height and weight values
height <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
weight <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)

# Create a dataframe
data <- data.frame(Height = height, Weight = weight)

# Perform linear regression (Weight ~ Height)
model <- lm(Weight ~ Height, data = data)

# Display regression summary
summary(model)

# Predict weight for a person with height 170
predicted_weight <- predict(model, data.frame(Height = 170))
cat("Predicted Weight for Height 170:", predicted_weight, "\n")

# Visualization of the regression model
ggplot(data, aes(x = Height, y = Weight)) +
  geom_point(color = "blue", size = 3) +  # Scatter plot
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Regression line
  annotate("point", x = 170, y = predicted_weight, color = "green", size = 4, shape = 17) +  # Predicted point
  annotate("text", x = 170, y = predicted_weight, label = paste("Predicted:", round(predicted_weight, 2)), vjust = -1, color = "green") +  # Label the predicted point
  labs(title = "Height vs Weight Linear Regression",
       x = "Height (cm)", 
       y = "Weight (kg)") +
  theme_minimal()

#-------------------------------------------------------------------------------------------------------------

#SET 17

# 1.a. Recursive function to generate Fibonacci sequence
fibonacci <- function(n) {
  if (n <= 0) {
    return(NA)
  } else if (n == 1) {
    return(0)
  } else if (n == 2) {
    return(1)
  } else {
    return(fibonacci(n - 1) + fibonacci(n - 2))
  }
}

# Function to print Fibonacci sequence up to 'num' terms
print_fibonacci <- function(num) {
  fib_sequence <- sapply(1:num, fibonacci)
  cat("Fibonacci sequence:", fib_sequence, "\n")
}

# Call function to print Fibonacci sequence up to 10 terms
print_fibonacci(10)

# 1.b. Sum of natural numbers up to 10 using a loop
sum_natural_numbers <- function(n) {
  sum <- 0
  for (i in 1:n) {
    sum <- sum + i
  }
  return(sum)
}

# Call function to find sum of first 10 natural numbers
cat("Sum of first 10 natural numbers:", sum_natural_numbers(10), "\n")

#-----------------------------------


# 2. Load the ChickWeight dataset
data("ChickWeight")
library(dplyr)

# 2.a. Summary of dataset
cat("Summary of ChickWeight Dataset:\n")
print(summary(ChickWeight))
cat("\nNumber of records per feature:\n")
print(str(ChickWeight))

# 2.b. Extract last 6 records of the dataset
cat("\nLast 6 records of ChickWeight dataset:\n")
print(tail(ChickWeight, 6))

# 2.c Order data by 'Diet' and then by 'weight'
ordered_data <- ChickWeight %>% arrange(Diet, weight)

# Print the first 10 records
print(head(ordered_data, 10))

#-----------------------------------

#3 
data("ChickWeight")
library(ggplot2)
library(dplyr)
# Install reshape2 if not installed
if (!requireNamespace("reshape2", quietly = TRUE)) install.packages("reshape2")

# Load required library
library(reshape2)

# 3.a. Perform melting based on Chick, Time, and Diet
melted_data <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))
cat("\nMelted Data:\n")
print(head(melted_data, 10))

# 3.b. Perform cast function to display mean weight grouped by Diet
mean_weight_by_diet <- dcast(melted_data, Diet ~ variable, mean)
cat("\nMean Weight grouped by Diet:\n")
print(mean_weight_by_diet)

# 3.c. Create Histogram for "Weight" feature belonging to Diet-2 category
ggplot(ChickWeight %>% filter(Diet == 2), aes(x = weight)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Weight for Diet-2", x = "Weight", y = "Frequency") +
  theme_minimal()


#-----------------------------------

# Ensure necessary libraries are loaded
library(ggplot2)
library(dplyr)
data("ChickWeight")
# 4.a. Create a multiple regression model (Weight ~ Time + Diet)
ChickWeight$Diet <- as.factor(ChickWeight$Diet)  # Ensure Diet is a factor
model <- lm(weight ~ Time + Diet, data = ChickWeight)
summary(model)

# 4.b. Predict weight for Time = 10 and Diet = 1
new_data <- data.frame(Time = 10, Diet = factor(1, levels = levels(ChickWeight$Diet)))  # Ensure Diet is a factor
predicted_weight <- predict(model, newdata = new_data)
cat("\nPredicted Weight for Time 10 and Diet-1:", predicted_weight, "\n")

# 4.c. Calculate error in model
actual_values <- ChickWeight %>%
  filter(Time == 10, Diet == "1") %>%
  select(weight)

error <- actual_values$weight - predicted_weight
cat("\nError in model for Time 10 and Diet-1:\n")
print(error)

#-------------------------------------------------------------------------------------------------------------

#SET 18

#1  multi-dimensional array
# Create a 3x4x2 multi-dimensional array
multi_array <- array(1:24, dim = c(3, 4, 2), 
                     dimnames = list(Rows = c("R1", "R2", "R3"), 
                                     Columns = c("C1", "C2", "C3", "C4"), 
                                     Depth = c("Layer1", "Layer2")))

# Print the array
print(multi_array)


# Explanation
cat("\nUsing meaningful dimension names improves readability and usability.\n")
cat("For example, in real-world applications like image processing, financial analysis,\n")
cat("or medical data, labeled dimensions help in easy interpretation and analysis.\n")

#-----------------------------------

# 2.a. Recursive function to generate Fibonacci sequence
fibonacci <- function(n) {
  if (n <= 0) {
    return(NA)
  } else if (n == 1) {
    return(0)
  } else if (n == 2) {
    return(1)
  } else {
    return(fibonacci(n - 1) + fibonacci(n - 2))
  }
}

# Function to print Fibonacci sequence up to 'num' terms
print_fibonacci <- function(num) {
  fib_sequence <- sapply(1:num, fibonacci)
  cat("Fibonacci sequence:", fib_sequence, "\n")
}

# Call function to print Fibonacci sequence up to 10 terms
print_fibonacci(10)

# 2.b. Sum of natural numbers up to 10 using a loop
sum_natural_numbers <- function(n) {
  sum <- 0
  for (i in 1:n) {
    sum <- sum + i
  }
  return(sum)
}

# Call function to find sum of first 10 natural numbers
cat("Sum of first 10 natural numbers:", sum_natural_numbers(10), "\n")

#-----------------------------------

#3(i). Order ChickWeight Data by weight (Grouped by Diet) and Extract Last 6 Records
# Load necessary library
library(dplyr)

# Load ChickWeight dataset
data("ChickWeight")

# Order data by weight (ascending), grouped by Diet
ordered_data <- ChickWeight %>% arrange(Diet, weight)

# Extract last 6 records
cat("\nLast 6 records from ordered data:\n")
print(tail(ordered_data, 6))

#3(ii). Perform Melting Function on ChickWeight
# Load necessary library
library(reshape2)

# Perform melting based on Chick, Time, and Diet
melted_data <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))

# Print first 10 rows of melted data
cat("\nMelted Data:\n")
print(head(melted_data, 10))

#-----------------------------------

#4. Logistic Regression on iris Dataset

# Load iris dataset
data(iris)

# Use only two species to make logistic regression binary
iris_binary <- subset(iris, Species %in% c("setosa", "versicolor"))

# Convert Species to binary factor
iris_binary$Species <- factor(iris_binary$Species)

# Split into training (80%) and testing (20%)
set.seed(123)
sample_index <- sample(1:nrow(iris_binary), 0.8 * nrow(iris_binary))
train_data <- iris_binary[sample_index, ]
test_data <- iris_binary[-sample_index, ]

# Build logistic regression model
model <- glm(Species ~ Petal.Length + Petal.Width, data = train_data, family = binomial)

# Predict probabilities on test data
predicted_prob <- predict(model, newdata = test_data, type = "response")

# Convert probabilities to class labels (threshold = 0.5)
predicted_classes <- ifelse(predicted_prob > 0.5, "versicolor", "setosa")
predicted_classes <- factor(predicted_classes, levels = levels(test_data$Species))

# Create confusion matrix using base R
actual <- test_data$Species
conf_matrix <- table(Predicted = predicted_classes, Actual = actual)

# Print confusion matrix
print(conf_matrix)

# Calculate accuracy
correct_predictions <- sum(diag(conf_matrix))
total_predictions <- sum(conf_matrix)
accuracy <- correct_predictions / total_predictions

# Print accuracy
cat("Accuracy:", round(accuracy * 100, 2), "%\n")



#-------------------------------------------------------------------------------------------------------------

#SET 19

#Q1: Dynamically extract subset from factor with random LETTERS
# Create a random sample from LETTERS (A to Z)
set.seed(123)
random_letters <- sample(LETTERS, 20, replace = TRUE)

# Convert to factor
letter_factor <- factor(random_letters)

# Display original factor levels
print(levels(letter_factor))

# Dynamically extract subset (example: pick 3 random unique levels)
subset_size <- 3
selected_levels <- sample(levels(letter_factor), subset_size)

# Subset factor based on selected levels
subset_result <- letter_factor[letter_factor %in% selected_levels]

# Output
cat("Selected levels:\n")
print(selected_levels)
cat("Subset based on selected levels:\n")
print(subset_result)

#-----------------------------------

#Q2: File input.csv & CSV Analysis
# Create data frame manually (simulating input.csv)
data <- data.frame(
  Name = c("Alice", "Bob", "Charlie", "David", "Eve"),
  Dept = c("HR", "IT", "Finance", "IT", "Marketing"),
  Salary = c(50, 70, 65, 80, 55)
)

# View the data
cat("Original Data Frame:\n")
print(data)

# a. Get the maximum salary
max_salary <- max(data$Salary)
cat("\nMaximum Salary:", max_salary, "\n")

# b. Get details of the person with the maximum salary
max_salary_person <- subset(data, Salary == max_salary)
cat("\nPerson with Maximum Salary:\n")
print(max_salary_person)

# c. Get all the people working in IT department
it_people <- subset(data, Dept == "IT")
cat("\nPeople in IT Department:\n")
print(it_people)

# d. Get persons in IT department with salary greater than 60
it_high_salary <- subset(data, Dept == "IT" & Salary > 60)
cat("\nIT Department with Salary > 60:\n")
print(it_high_salary)


#-----------------------------------

#Q3: Random integers from -50 to +50, analyze distribution
# Generate 10 random integers between -50 and 50
set.seed(100)
random_numbers <- sample(-50:50, 10, replace = TRUE)
print(random_numbers)

# Analyze distribution
summary(random_numbers)
hist(random_numbers, col = "lightblue", main = "Distribution of Random Numbers")

# Modify code for all positive values (e.g., 10 to 50)
positive_randoms <- sample(10:50, 10, replace = TRUE)
print(positive_randoms)

#-----------------------------------

#Q4a: Fibonacci sequence using recursion
fibonacci <- function(n) {
  if (n <= 1) {
    return(n)
  } else {
    return(fibonacci(n - 1) + fibonacci(n - 2))
  }
}

# Print Fibonacci sequence up to 10 terms
cat("Fibonacci sequence:\n")
for (i in 0:9) {
  cat(fibonacci(i), " ")
}
cat("\n")

#Q4b: Sum of natural numbers up to 10 using loop
sum_val <- 0
for (i in 1:10) {
  sum_val <- sum_val + i
}
cat("Sum of natural numbers up to 10:", sum_val, "\n")

------------------------------------------------------------------------------------------------
