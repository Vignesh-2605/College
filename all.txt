# 1 The intervals and corresponding frequencies are as follows. age frequency
intervals <- list(c(1,5), c(5,15), c(15,20), c(20,50), c(50,80), c(80,110))
frequencies <- c(200, 450, 300, 1500, 700, 44)

# Compute cumulative frequencies
cumulative_freq <- cumsum(frequencies)
N <- sum(frequencies)
N_half <- N / 2  # Find median position

# Find the median class
median_class_index <- which(cumulative_freq >= N_half)[1]
median_class <- intervals[[median_class_index]]

# Extract values
L <- median_class[1]  # Lower boundary
F <- ifelse(median_class_index == 1, 0, cumulative_freq[median_class_index - 1]) # Cumulative frequency before median class
f <- frequencies[median_class_index]  # Frequency of median class
h <- median_class[2] - median_class[1]  # Class width

# Compute median using formula
median_value <- L + ((N_half - F) / f) * h

# Print the result
cat("Approximate Median Age:", median_value, "\n")
--------------------------------------------------------------------------------------------------------------------     
                                    
#2 mean , median , mode , midrange , quantile
# Given data
data <- c(13, 15, 16, 16, 19, 20, 20, 21, 22, 22, 25, 25, 25, 25, 30, 33, 
          33, 35, 35, 35, 35, 36, 40, 45, 46, 52, 70)
# Mean
mean_value <- mean(data)
cat("Mean:", mean_value, "\n")
# Median
median_value <- median(data)
cat("Median:", median_value, "\n")
# Mode function (to find most frequent values)
get_mode <- function(x) {
  uniq_vals <- unique(x)
  freq <- tabulate(match(x, uniq_vals))
  uniq_vals[freq == max(freq)]
}
mode_value <- get_mode(data)
cat("Mode:", mode_value, "\n")
# Midrange
midrange_value <- (min(data) + max(data)) / 2
cat("Midrange:", midrange_value, "\n")
# Quartiles
q1 <- quantile(data, 0.25)
q3 <- quantile(data, 0.75)
cat("First Quartile (Q1):", q1, "\n")
cat("Third Quartile (Q3):", q3, "\n")
--------------------------------------------------------------------------------------------------------------------  

#3 Min-Max Normalization , Z-Score Normalization
# Given data
data <- c(200, 300, 400, 600, 1000)
scale(data)
# Min-Max Normalization (0 to 1)
min_max_normalized <- (data - min(data)) / (max(data) - min(data))
# Z-Score Normalization
mean_val <- mean(data)
sd_val <- sd(data)
z_score_normalized <- (data - mean_val) / sd_val
# Print results
cat("Min-Max Normalization:\n", min_max_normalized, "\n")
cat("Z-Score Normalization:\n", z_score_normalized, "\n")

--------------------------------------------------------------------------------------------------------------------  
#4 Smoothing by Bin Mean , Smoothing by Bin Median , Smoothing by Bin Boundaries
# Given data
data <- c(11,13,13,15,15,16,19,20,20,20,21,21,22,23,24,30,40,45,45,45,71,72,73,75)

# Define bins (4 bins)
bins <- split(data, ceiling(seq_along(data)/6)) 
  
# Smoothing by Bin Mean
bin_mean <- lapply(bins, function(bin) rep(mean(bin), length(bin)))
smoothed_mean <- unlist(bin_mean)

# Smoothing by Bin Median
bin_median <- lapply(bins, function(bin) rep(median(bin), length(bin)))
smoothed_median <- unlist(bin_median)

# Smoothing by Bin Boundaries
bin_boundaries <- lapply(bins, function(bin) {
  lower <- min(bin)
  upper <- max(bin)
  sapply(bin, function(x) ifelse(abs(x - lower) < abs(x - upper), lower, upper))
})
smoothed_boundaries <- unlist(bin_boundaries)

# Print results
cat("Smoothed by Bin Mean:\n", smoothed_mean, "\n")
cat("Smoothed by Bin Median:\n", smoothed_median, "\n")
cat("Smoothed by Bin Boundaries:\n", smoothed_boundaries, "\n")
-------------------------------------------------------------------------------------------------------------------- 
#5 Analyze age and %fat data with mean, median, SD, boxplots, and plots.
age <- c(23,23,27,27,39,41,47,49,50,52,54,54,56,57,58,58,60,61)
fat <- c(9.5,26.5,7.8,17.8,31.4,25.9,27.4,27.2,31.2,34.6,42.5,28.8,33.4,30.2,34.1,32.9,41.2,35.7)

# (a) Descriptive statistics
age_mean <- mean(age)
age_median <- median(age)
age_sd <- sd(age)

fat_mean <- mean(fat)
fat_median <- median(fat)
fat_sd <- sd(fat)

# (b) Boxplots
par(mfrow=c(1,2))
boxplot(age, main="Age Boxplot")
boxplot(fat, main="%Fat Boxplot")

# (c) Scatter plot and Q-Q plot
plot(age, fat, main="Age vs %Fat Scatterplot")
qqnorm(age); qqline(age)
qqnorm(fat); qqline(fat)

-------------------------------------------------------------------------------------------------------------------- 
#6 Normalize age value 35 using different methods.
age <- c(23,23,27,27,39,41,47,49,50,52,54,54,56,57,58,58,60,61)
min_max_35 <- (35 - min(age)) / (max(age) - min(age))
z_score_35 <- (35 - mean(age)) / 12.94
decimal_35 <- 35 / 100  # since max is 61, we use 10^2=100
min_max_35
z_score_35
print(paste("decimal = ",decimal_35))
-------------------------------------------------------------------------------------------------------------------- 

#7 Create a vector for the number of pencils mean , median , mode
  # Create a vector for the number of pencils
pencils <- c(9, 25, 23, 12, 11, 6, 7, 8, 9, 10)

# Compute mean, median, and mode
mean_value <- mean(pencils)
median_value <- median(pencils)
get_mode <- function(x) {
  uniq_vals <- unique(x)
  freq <- tabulate(match(x, uniq_vals))
  uniq_vals[freq == max(freq)]
}
mode_val <- get_mode(pencils)
# Print results
cat("Mean:", mean_value, "\nMedian:", median_value, "\nMode:", mode_val, "\n")
--------------------------------------------------------------------------------------------------------------------
#8 plot x- Mobile phones sold , y - Money earned
# Data points
x <- c(4, 1, 5, 7, 10, 2, 50, 25, 90, 36)  # Mobile phones sold
y <- c(12, 5, 13, 19, 31, 7, 153, 72, 275, 110)  # Money earned
# Scatter plot
plot(x, y, main="Scatter Plot of Mobile Phones Sold vs Money Earned",
     xlab="Mobile Phones Sold", ylab="Money Earned", col="blue", pch=19)
grid()

--------------------------------------------------------------------------------------------------------------------
#9 Equal-Frequency,Equal-Width Partitioning,Histogram Plot, school model exam mark

# Given marks data (sorted)
marks <- c(55, 60, 71, 63, 55, 65, 50, 55, 58, 59, 61, 63, 65, 67, 71, 72, 75)

# (a) Equal-Frequency (Equi-depth) Partitioning
bins_freq <- split(sort(marks), ceiling(seq_along(marks) / (length(marks) / 3)))

# (b) Equal-Width Partitioning
range_marks <- range(marks)
bin_width <- (range_marks[2] - range_marks[1]) / 3
bins_width <- cut(marks, breaks=seq(range_marks[1], range_marks[2], by=bin_width), include.lowest=TRUE)

# Histogram Plot
hist(marks, main="Histogram of Marks", xlab="Marks", col="lightblue", border="black", breaks=5)
grid()

# Print bin partitions
cat("Equal-Frequency Bins:\n"); print(bins_freq)
cat("Equal-Width Bins:\n"); print(table(bins_width))

-------------------------------------------------------------------------------------------------------------------- 
#10  Calculate Interquartile Range,Standard Deviation
# Given speed data
speed <- c(78.3, 81.8, 82, 74.2, 83.4, 84.5, 82.9, 77.5, 80.9, 70.6)

# Calculate Interquartile Range (IQR)
iqr_value <- IQR(speed)

# Calculate Standard Deviation
sd_value <- sd(speed)

# Print results
cat("Interquartile Range (IQR):", iqr_value, "\nStandard Deviation:", sd_value, "\n")

-------------------------------------------------------------------------------------------------------------------- 
#11 quantile 
data = c(13, 15, 16, 16, 19, 20, 20, 21, 22, 22, 25, 25, 25, 25, 30,33, 33, 35, 35, 35, 35, 36, 40, 45, 46, 52, 70)
q1 <- quantile(data,0.25)
q2 <- quantile(data,0.75)
print(q1)
print(q2)

-------------------------------------------------------------------------------------------------------------------- 
#12 Covariance andcorrelation
# Given data
preferences <- data.frame(
    A = c(18, 2, 20),
    B = c(22, 28, 10),
    C = c(20, 40, 40)
  )

# 1. Sample covariance between B and C
cov_BC <- cov(preferences$B, preferences$C)

# 2. Sample covariance matrix for preferences
cov_matrix <- cov(preferences)

# 3. Sample correlation between B and C
cor_BC <- cor(preferences$B, preferences$C)

# 4. Sample correlation matrix for preferences
cor_matrix <- cor(preferences)

# Print results
cat("Covariance between B and C:", cov_BC, "\n\n")
cat("Covariance matrix:\n"); print(cov_matrix)
cat("\nCorrelation between B and C:", cor_BC, "\n\n")
cat("Correlation matrix:\n"); print(cor_matrix)

-------------------------------------------------------------------------------------------------------------------- 

#13 Electronics bin mean , bin boundary , histogram
  # Given price data
prices <- c(1, 1, 5, 5, 5, 5, 5, 8, 8, 10, 10, 10, 10, 12, 14, 14, 14, 15, 15, 15, 15, 15, 15, 
              18, 18, 18, 18, 18, 18, 18, 18, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 25, 25, 
              25, 25, 25, 28, 28, 30, 30, 30)

# (i) Equal-Frequency Partitioning (bin size = 3)
num_bins <- 3
bin_size <- length(prices) / num_bins
bins_eq_freq <- split(sort(prices), ceiling(seq_along(prices) / bin_size))

# (ii) Data Smoothing
# Bin Means
bin_means <- lapply(bins_eq_freq, mean)

# Bin Boundaries
bin_boundaries <- lapply(bins_eq_freq, function(bin) {
  min_val <- min(bin)
  max_val <- max(bin)
  ifelse(bin == min_val | bin == max_val, bin, ifelse(abs(bin - min_val) < abs(bin - max_val), min_val, max_val))
})

# (iii) Histogram Plot
hist(prices, main="Histogram of Prices", xlab="Price", col="lightblue", border="black", breaks=10)
grid()

# Print results
cat("Equal-Frequency Bins:\n"); print(bins_eq_freq)
cat("\nBin Means:\n"); print(bin_means)
cat("\nBin Boundaries:\n"); print(bin_boundaries)

#-------------------------------------------------------------------------------------------------------------------- 

#14 boxplot
# Given scores for Class A and Class B
class_A <- c(76, 35, 47, 64, 95, 66, 89, 36, 84)
class_B <- c(51, 56, 84, 60, 59, 70, 63, 66, 50)

# (i) Calculate mean, median, and range for each class
mean_A <- mean(class_A)
median_A <- median(class_A)
range_A <- range(class_A)
range_A_value <- diff(range_A)

mean_B <- mean(class_B)
median_B <- median(class_B)
range_B <- range(class_B)
range_B_value <- diff(range_B)

# Print results
cat("Class A - Mean:", mean_A, ", Median:", median_A, ", Range:", range_A_value, "\n")
cat("Class B - Mean:", mean_B, ", Median:", median_B, ", Range:", range_B_value, "\n")

# (ii) Boxplot
boxplot(class_A, class_B, names = c("Class A", "Class B"), col = c("lightblue", "lightgreen"),
        main = "Boxplot of Exam Scores", ylab = "Scores")

# Grid for better readability
grid()

#-------------------------------------------------------------------------------------------------------------------- 

#15
# (a) Min-Max Normalization
min_val <- 200
max_val <- 1000
data <- c(200, 300, 400, 600, 1000)

min_max_norm <- (data - min_val) / (max_val - min_val)

# (b) Z-Score Normalization
mean_val <- mean(data)
sd_val <- sd(data)
z_score_norm <- (data - mean_val) / sd_val

# Print results
cat("Min-Max Normalization:\n", min_max_norm, "\n")
cat("Z-Score Normalization:\n", z_score_norm, "\n")

#-------------------------------------------------------------------------------------------------------------------- 

#16 AirPassengers dataset question
# Load AirPassengers dataset

data("AirPassengers")

# Convert to numeric vector
passengers <- as.numeric(AirPassengers)

# Define breaks (bins) from 100 to 700 with a width of 150
breaks_seq <- seq(100, 700, by = 150)

# Create histogram
hist(passengers, breaks = breaks_seq, col = "lightblue", border = "black",
     main = "Histogram of AirPassengers Dataset", xlab = "Number of Passengers")

# Add grid for better readability
grid()

#-------------------------------------------------------------------------------------------------------------------- 

#17 mtcars dataset
# Load dataset
data("mtcars")

# Plot multiple lines in a single plot
plot(mtcars$mpg, type = "o", col = "blue", ylim = range(c(mtcars$mpg, mtcars$qsec)),
     xlab = "Index", ylab = "Values", main = "Multiple Lines in Line Chart")

# Add second line
lines(mtcars$qsec, type = "o", col = "red")

# Add legend
legend("topright", legend = c("MPG", "QSEC"), col = c("blue", "red"), lty = 1, pch = 1)

#-------------------------------------------------------------------------------------------------------------------- 

#18

# Install & load the "water" dataset
install.packages("faraway")  # Install only if not available
library(faraway)
data("water")

# Scatter plot to check linear relation
plot(water$hardness, water$mortality, main = "Mortality vs Hardness",
     xlab = "Hardness", ylab = "Mortality", col = "blue", pch = 16)

# Fit linear regression model
model <- lm(mortality ~ hardness, data = water)

# Add regression line to plot
abline(model, col = "red", lwd = 2)

# Predict mortality for hardness = 88
predicted_mortality <- predict(model, newdata = data.frame(hardness = 88))
cat("Predicted Mortality for Hardness = 88:", predicted_mortality, "\n")

#-------------------------------------------------------------------------------------------------------------------- 

#19 MTCARS MPG Cyl

# Load mtcars dataset
data("mtcars")

# Create boxplot for mpg grouped by cyl
boxplot(mpg ~ cyl, data = mtcars, col = c("lightblue", "lightgreen", "pink"),
        main = "MPG vs Number of Cylinders", xlab = "Number of Cylinders",
        ylab = "Miles per Gallon (MPG)")

#-------------------------------------------------------------------------------------------------------------------- 

#20 tennis example boxplot
# Sample data for points scored by players
player_scores <- c(10, 12, 15, 18, 21, 30, 35, 40, 45, 50, 60, 100)

# Create boxplot
boxplot(player_scores, col = "lightblue", main = "Tennis Player Scores",
        ylab = "Scores", horizontal = TRUE)

# Add text annotation for outliers
outliers <- boxplot.stats(player_scores)$out
if (length(outliers) > 0) {
  text(rep(1.2, length(outliers)), outliers, labels = outliers, col = "red", pos = 4)
}

#-------------------------------------------------------------------------------------------------------------------- 

#21 Scatterplot & Bar Chart for Blood Pressure vs Age (Diabetes Dataset)
# Load diabetes dataset
diabetes <- read.csv("diabetes.csv")

# Scatterplot: Age vs BloodPressure
plot(diabetes$Age, diabetes$BloodPressure, main = "Blood Pressure vs Age",
     xlab = "Age", ylab = "Blood Pressure", col = "blue", pch = 16)

# Bar chart for Age groups
age_groups <- cut(diabetes$Age, breaks = seq(20, 80, by = 10), right = FALSE)
barplot(tapply(diabetes$BloodPressure, age_groups, mean), col = "lightgreen",
        main = "Average Blood Pressure by Age Group", xlab = "Age Group",
        ylab = "Average Blood Pressure")


#-------------------------------------------------------------------------------------------------------------------- 

# diabetes question
# Load necessary library
library(ggplot2)

# Read the diabetes dataset
setwd("C:/Users/antoc/OneDrive/Desktop/dwdm capestoone/dwdm r")
diabetes <- read.csv("diabetes.csv")

# Scatterplot: Age vs Blood Pressure
ggplot(diabetes, aes(x = Age, y = BloodPressure)) +
  geom_point(color = "blue", alpha = 0.6) +
  labs(title = "Scatterplot of Blood Pressure vs Age",
       x = "Age",
       y = "Blood Pressure") +
  theme_minimal()

# Create Age groups for bar chart
diabetes$AgeGroup <- cut(diabetes$Age, breaks = seq(20, 80, by = 10), right = FALSE)

# Bar chart: Average Blood Pressure by Age Group
bp_avg <- aggregate(BloodPressure ~ AgeGroup, data = diabetes, mean)

ggplot(bp_avg, aes(x = AgeGroup, y = BloodPressure, fill = AgeGroup)) +
  geom_bar(stat = "identity", color = "black") +
  labs(title = "Average Blood Pressure by Age Group",
       x = "Age Group",
       y = "Average Blood Pressure") +
  theme_minimal() +
  theme(legend.position = "none")

diabetes.csv
Age,BloodPressure,Glucose,Insulin,BMI
25,80,100,15,22.5
35,85,120,20,24.8
45,90,140,25,26.1
55,95,160,30,27.4
65,100,180,35,28.9

#-------------------------------------------------------------------------------------------------------------------- 

# breast cancer
# Load necessary library
library(ggplot2)

# Create a sample dataset
set.seed(123)  # For reproducibility
breast_cancer <- data.frame(
  Age = sample(20:80, 50, replace = TRUE),  # Age between 20 to 80
  TumorSize = sample(1:10, 50, replace = TRUE),  # Tumor size (1-10 cm)
  V_Nodes = sample(0:15, 50, replace = TRUE)  # Affected lymph nodes (0-15)
)

# View first few rows
head(breast_cancer)

# Histogram of Age Distribution
ggplot(breast_cancer, aes(x = Age)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Age Distribution of Breast Cancer Patients",
       x = "Age",
       y = "Count") +
  theme_minimal()

# Scatter Plot of Tumor Size vs Age
ggplot(breast_cancer, aes(x = Age, y = TumorSize)) +
  geom_point(color = "red", size = 3, alpha = 0.6) +
  labs(title = "Scatter Plot of Tumor Size vs Age",
       x = "Age",
       y = "Tumor Size (cm)") +
  theme_minimal()

# Box Plot of Tumor Size by Age Groups
breast_cancer$AgeGroup <- cut(breast_cancer$Age, breaks = seq(20, 80, by = 10), right = FALSE)

ggplot(breast_cancer, aes(x = AgeGroup, y = TumorSize, fill = AgeGroup)) +
  geom_boxplot() +
  labs(title = "Boxplot of Tumor Size by Age Group",
       x = "Age Group",
       y = "Tumor Size (cm)") +
  theme_minimal() +
  theme(legend.position = "none")

#-------------------------------------------------------------------------------------------------------------------- 

# (cricket) Perform different normalizations on strike rates: 100, 70, 60, 90, 90.(z-score with mean absolute deviation)
strike_rates <- c(100, 70, 60, 90, 90)

# (a) Min-Max normalization
min_max <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}
min_max_norm <- min_max(strike_rates)

# (b) z-score normalization
z_score_norm <- scale(strike_rates)

# (c) z-score with mean absolute deviation
mad <- mean(abs(strike_rates - mean(strike_rates)))
mad_norm <- (strike_rates - mean(strike_rates)) / mad

# (d) decimal scaling
decimal_scale <- function(x) {
  x / (10^ceiling(log10(max(abs(x)))))
}
decimal_norm <- decimal_scale(strike_rates)

results <- data.frame(
  Original = strike_rates,
  MinMax = min_max_norm,
  ZScore = z_score_norm,
  ZScore_MAD = mad_norm,
  Decimal = decimal_norm
)
print(results)

#-------------------------------------------------------------------------------------------------------------------- 

#Vegetarians yes or no
# Create a data frame with person names and vegetarian status
persons <- data.frame(
  Name = c("Gopu", "Babu", "Baby", "Gopal", "Krishna", "Jai", "Dev", "Malini", "Hema", "Anu"),
  Vegetarian = c("yes", "yes", "yes", "no", "yes", "no", "no", "yes", "yes", "yes")
)

# Count the number of vegetarians and non-vegetarians
veg_count <- sum(persons$Vegetarian == "yes")
non_veg_count <- sum(persons$Vegetarian == "no")

# Print the results
cat("Number of Vegetarians:", veg_count, "\n")
cat("Number of Non-Vegetarians:", non_veg_count, "\n")

# Find which type is greater
if (veg_count > non_veg_count) {
  cat("Vegetarians are greater in number.\n")
} else if (veg_count < non_veg_count) {
  cat("Non-Vegetarians are greater in number.\n")
} else {
  cat("Both have equal numbers.\n")
}

#-------------------------------------------------------------------------------------------------------------------- 


# Create vectors for x (number of phones sold) and y (money earned)
x <- c(4, 1, 5, 7, 10, 2, 50, 25, 90, 36)
y <- c(12, 5, 13, 19, 31, 7, 153, 72, 275, 110)

# Create a scatter plot
plot(x, y, main = "Scatter Plot of Mobile Phones Sold vs. Money Earned",
     xlab = "Number of Mobile Phones Sold", ylab = "Money Earned",
     col = "blue", pch = 16)

# Add a trend line (optional)
abline(lm(y ~ x), col = "red", lwd = 2)

##-------------------------------------------------------------------------------------------------------------------- 

# Partition 12 sales prices (5,10,11,13,15,35,50,55,72,92,204,215) into bins.
prices <- c(5,10,11,13,15,35,50,55,72,92,204,215)

# (a) Equal-frequency (3 bins)
bin_ef <- cut(prices, breaks=3, labels=c("Low","Medium","High"))

# (b) Equal-width
bin_ew <- cut(prices, breaks=seq(min(prices), max(prices), length.out=4), 
              labels=c("Low","Medium","High"))

# (c) Clustering
kmeans_result <- kmeans(matrix(prices, ncol=1), centers=3)
bin_cluster <- factor(kmeans_result$cluster)

results <- data.frame(Price=prices, EqualFreq=bin_ef, 
                      EqualWidth=bin_ew, Cluster=bin_cluster)
print(results)


#-------------------------------------------------- WEKA ------------------------------------------------------------------------

2. Employee Clustering using K-Means (Problem 2)
EmployeeID,Gender,Age,Salary,Credit
111,Male,28,150000,39
222,Male,25,150000,27
333,Female,26,160000,42
444,Female,25,160000,40
555,Female,30,170000,64
666,Male,29,200000,72

Weka Steps:

Load CSV file

Select "Cluster" tab

Choose "SimpleKMeans"

Set numClusters=3 (or experiment with different values)

Select attributes: Salary and Credit

Run clustering

Visualize results

Right-click result in list → "Visualize cluster assignments"
--------------------------------------------------------------------------------------
FP-Growth Algorithm Supermarket
@RELATION supermarket

@ATTRIBUTE Bread  {0,1}
@ATTRIBUTE Cheese {0,1}
@ATTRIBUTE Egg    {0,1}
@ATTRIBUTE Juice  {0,1}
@ATTRIBUTE Milk   {0,1}
@ATTRIBUTE Yogurt {0,1}

@DATA
1,1,1,1,0,0  % Transaction 1: Bread, Cheese, Egg, Juice
1,1,0,1,0,0  % Transaction 2: Bread, Cheese, Juice
1,0,0,0,1,1  % Transaction 3: Bread, Milk, Yogurt
1,0,0,1,1,0  % Transaction 4: Bread, Juice, Milk
0,1,0,1,1,0  % Transaction 5: Cheese, Juice, Milk

---------------------------------------------------------------------------------------
Decision Tree Analysis Gender
@RELATION gender_pred

@ATTRIBUTE height NUMERIC
@ATTRIBUTE weight NUMERIC
@ATTRIBUTE gender {Male,Female}

@DATA
185,85,Male
175,75,Female
182,82,Male
168,68,Female
190,90,Male
170,70,Female

-----------------------------------------------------------------------------
Association Rule Mining (Apriori and FP-Growth) ABCDE

@RELATION transactions
@ATTRIBUTE items {a,b,c,d,e}
@DATA
{a,d,e}
{a,b,c,e}
{a,b,d,e}
{a,c,d,e}
{b,c,e}
{b,d,e}
{c,d}
{a,b,c}
{a,d,e}
{a,b,e}

-----------------------------------------------------------------------
Transaction Analysis (M,O,N,K,E,Y)

@relation transactions

@attribute M {0,1}
@attribute O {0,1}
@attribute N {0,1}
@attribute K {0,1}
@attribute E {0,1}
@attribute Y {0,1}
@attribute D {0,1}
@attribute A {0,1}
@attribute U {0,1}
@attribute C {0,1}
@attribute I {0,1}

@data
1,1,1,1,1,1,0,0,0,0,0  % T1 (M, O, N, K, E, Y)
0,1,1,1,1,1,1,0,0,0,0  % T2 (D, O, N, K, E, Y)
1,0,0,1,1,0,0,1,0,0,0  % T3 (M, A, K, E)
1,0,0,1,0,1,0,0,1,1,0  % T4 (M, U, C, K, Y)
0,1,0,1,1,0,0,0,0,1,1  % T5 (C, O, O, K, I, E)


-----------------------------------------------------------------------
Hot Dogs Transaction Analysis

@RELATION supermarket
@ATTRIBUTE items {Hot_Dogs,Buns,Ketchup,Coke,Chips}
@DATA
Hot_Dogs,Buns,Ketchup
Hot_Dogs,Buns
Hot_Dogs,Coke,Chips
Chips,Coke
Chips,Ketchup
Hot_Dogs,Coke,Chips

---------------------------------------------------------------------------------------
#1 Create an ARFF file for the given transaction table and implement Apriori and FP-Growth algorithms with min support=2 and confidence=50%, then compare the rules.

@RELATION transactions

@ATTRIBUTE items {SONY,BPL,LG,SAMSUNG,ONIDA}

@DATA
SONY,BPL,LG
BPL,SAMSUNG
BPL,ONIDA
SONY,BPL,SAMSUNG
SONY,ONIDA
BPL,ONIDA
SONY,ONIDA
SONY,BPL,ONIDA,LG
SONY,BPL,ONIDA

---------------------------------------------------------------------
#9 Create ARFF file and compare Naive Bayes with Decision Tree.
@RELATION PlayTennis

@ATTRIBUTE Outlook {Sunny,Overcast,Rain}
@ATTRIBUTE Temperature {Hot,Mild,Cool}
@ATTRIBUTE Humidity {High,Normal}
@ATTRIBUTE Wind {Weak,Strong}
@ATTRIBUTE PlayTennis {Yes,No}

@DATA
Sunny,Hot,High,Weak,No
Sunny,Hot,High,Strong,No
Overcast,Hot,High,Weak,Yes
Rain,Mild,High,Weak,Yes
Rain,Cool,Normal,Weak,Yes
Rain,Cool,Normal,Strong,No
Overcast,Cool,Normal,Strong,Yes
Sunny,Mild,High,Weak,No
Sunny,Cool,Normal,Weak,Yes
Rain,Mild,Normal,Weak,Yes
Sunny,Mild,Normal,Strong,Yes
Overcast,Mild,High,Strong,Yes
Overcast,Hot,Normal,Weak,Yes
Rain,Mild,High,Strong,No

--------------------------------------------------------------------------
